# TruAI Architecture Documentation

## 전체 흐름 한 줄 요약

1. **UI**: 사용자가 "심층 리서치 결과 URL" 넣음 → 파싱된 문단 리스트와 문단별 출처 링크를 실시간으로 그림 → 이후 문단별 신뢰도 업데이트 수신하면 색만 갈아끼움.
2. **백엔드 로직1 (Ingest/파싱)**: 입력 URL → ScrapingBee로 원문 수집 → 본문 vs 출처/주석 분리 → 문단+해당 링크 매핑 → 이 구조를 **즉시 UI에 반환** + 동시에 **백엔드 로직2에 job으로 넘김**.
3. **백엔드 로직2 (검증/평가)**: 문단별로 링크 최대 5개까지 ScrapingBee 병렬 크롤링 → 문단+원문링크 텍스트 → GPT 호출로 신뢰도 산정/근거 요약 → 문단ID별로 부분 푸시 → UI가 실시간 반영.

---

## 공통으로 먼저 고정할 것 (계약서 같은 것)

### 1) 문단 단위 데이터 구조 (로직1 → UI, 로직1 → 로직2)

```json
{
  "doc_id": "string",
  "source_url": "https://original-deep-research-url",
  "paragraphs": [
    {
      "id": 1,
      "order": 1,
      "text": "해당 문단 내용...",
      "links": [
        "https://example.com",
        "https://example2.com"
      ]
    }
  ]
}
```

- **UI는 이걸 받는 즉시 뿌린다.**
- **백엔드 로직2는 이걸 job payload로 그대로 쓴다.**

### 2) 문단 검증 결과 구조 (로직2 → UI)

```json
{
  "doc_id": "string",
  "paragraph_id": 1,
  "confidence": "high",  // high | medium | low
  "summary_of_sources": "해당 문단은 2/2개의 출처와 일치합니다...",
  "reasoning": "example.com에서는 A라고 하고, example2.com에서도 B라고 하여...",
  "link_digests": [
    {
      "url": "https://example.com",
      "title": "원문 제목(없으면 URL)",
      "summary": "원문 크롤링 요약"
    }
  ]
}
```

- UI는 `paragraph_id` 기준으로 찾아서 신호등 색만 바꾸고, 마우스오버용 팝오버에 `summary_of_sources` + `link_digests` 넣으면 끝.

이 2개만 먼저 합의되면 3트랙이 동시에 갈 수 있어요.

---

## 1. UI 트랙

### 목표

- URL 입력 → 문단 리스트를 **스켈레톤 형태로 먼저** 보여주고
- 이후 문단별 평가 결과가 올 때마다 해당 카드 색을 바꾸고 툴팁을 붙인다.

### 할 일

1. **페이지 레이아웃**
    - 상단: URL 입력 + "분석하기" 버튼
    - 좌측(메인): 문단 카드 리스트
    - 우측/혹은 카드 안 팝오버: 출처/판단근거
2. **문단 카드 컴포넌트**
    - 기본 상태: 회색("평가중…")
    - props: `id, order, text, links, status, tooltipData`
    - status별 색:
        - high: 초록
        - medium: 노랑
        - low: 빨강
3. **마우스오버/아이콘**
    - 카드 우측 상단에 "i" 아이콘
    - hover 시:
        - "참조한 링크들"
        - 각 링크의 요약
        - GPT 판단 근거
4. **API 연동**
    - `POST /api/ingest` 로 URL 보냄 → 위의 "문단 구조" 받으면 바로 렌더
    - 이후 **SSE / WebSocket / 폴링** 중 하나로
        - `paragraph_id` 단위 업데이트 받기
        - 받아서 해당 카드만 re-render
    - (초기 버전은 3초 폴링으로 가도 OK: `GET /api/verification?doc_id=...&after=timestamp`)
5. **에러/로딩 상태**
    - URL이 잘못됐을 때
    - 문단은 왔는데 검증이 오래 걸릴 때("출처 검증 중…" 뱃지)

### UI 트랙이 필요로 하는 것

- API 스펙만 있으면 목데이터로 시작 가능
- 처음에는 **정적 JSON** 으로 개발 → 나중에 실서버 붙이기

---

## 2. 백엔드 로직1 트랙 (URL → 문단/출처 분리)

### 역할

- 외부 URL을 받아 **보기 좋은 구조**로 정리해서 UI와 로직2에 동시에 뿌리는 "입구" 레이어

### 처리 단계

1. **입력 수신**
    - `POST /api/ingest`
    - body: `{ "url": "https://..." }`
    - 응답은 **가능한 한 빨리** 반환해야 UI가 뜬다.
2. **ScrapingBee 호출**
    - URL을 ScrapingBee로 가져오기
    - 옵션: JS 렌더 필요하면 `render_js=true`
    - 가져온 HTML을 파서에 넘김
3. **본문 vs 출처/주석 분리**
    - 심층 리서치 공유 페이지 구조를 몇 개 샘플링해서 룰 베이스로 먼저 구현
        - 예: `References`, `출처`, `Footnotes`, 번호달린 리스트, `data-footnote` 등
    - 본문은 `<main>` 또는 주요 콘텐츠 영역 우선
4. **문단 단위 분할**
    - 기준:
        - `<p>`, `<li>`, `<h2>+p` 묶음, `<section>` 등
        - 너무 짧으면 이전 문단에 붙이기
        - 너무 길면 500~800자 기준으로 쪼개기
5. **문단 ↔ 출처 링크 매칭**
    - 패턴 1: 본문 안에 직접 `<a>` 가 있는 경우 → 그 문단의 링크로
    - 패턴 2: 본문 안에 [1], [2] 같은 번호 → 아래쪽 주석 섹션에서 동일 번호 찾아 매핑
    - 패턴 3: 아무것도 없을 때 → 문서 전체 공통 출처로 표시
6. **결과 구성 후 반환**
    - 위에서 정한 구조로 `doc_id` 생성해서 응답 보내기
    - 동시에 **로직2에 Job push**
        - ex) 메시지큐(Kafka, SQS, Redis stream) or 단순 DB status row 생성

### API 예시

```
POST /api/ingest
-> 200 OK
{
  "doc_id": "doc_20251101_abcd",
  "paragraphs": [ ... ],
  "source_url": "..."
}
```

### 이 트랙이 끝나면

- UI는 이미 화면이 보임
- 로직2는 "뭘 검증해야 하는지" 아는 상태

---

## 3. 백엔드 로직2 트랙 (출처 신뢰도 평가 + 문단 검증)

### 역할

- 문단 하나를 기준으로
    1. 거기에 달린 링크 최대 5개 크롤
    2. 각 **출처의 신뢰도**를 먼저 평가 (도메인, 저자, 발행기관 등)
    3. 각 링크 본문 요약
    4. "문단 내용"과 "링크 요약들"을 GPT한테 던져서
        - 일치도 / 누락 / 과장 / 반전 여부 체크
        - 출처 신뢰도와 내용 일치도를 종합하여 최종 신뢰도(상/중/하) 매기기
    5. 그 결과를 UI로 스트리밍/푸시

### 처리 단계

1. **Job 수신**
    - 로직1이 넣어둔 `doc_id`, `paragraphs[]` 를 가져옴
    - paragraphs 반복
2. **링크 크롤링 (최대 5개 병렬)**
    - 각 링크에 대해 ScrapingBee 호출
    - 응답 길면 앞부분 2~3k 토큰만
    - 실패 시 "해당 링크를 열 수 없어 신뢰도에 불리하게 반영" 플래그
3. **출처 신뢰도 평가 (1차)**
    - 각 링크의 도메인, 발행기관, 저자 정보 추출
    - 출처 유형 분류:
        - 학술 논문 (arxiv, doi.org, 학술지)
        - 공식 기관 (정부, 연구소, 대학)
        - 언론사 (신뢰도 높은 매체 vs 일반 블로그)
        - 소셜 미디어/개인 블로그 (낮은 신뢰도)
    - GPT에 출처 메타데이터 전달하여 `source_credibility: high|medium|low` 평가
4. **프롬프트 구성 (GPT)**
    - 시스템: "너는 사실 검증기…"
    - 유저:
        - 문단 원문
        - 각 링크의 출처 신뢰도 평가 결과
        - 링크별 요약 텍스트 (직접 요약 or 단순 truncate)
        - 지시: "출처 신뢰도와 내용 일치도를 모두 고려하여 평가. 신뢰도 높은 출처의 내용 일치가 중요하며, 낮은 신뢰도 출처는 가중치를 낮춰라"
    - 모델 응답 포맷을 **JSON 강제**
        
        ```json
        {
          "overall_confidence": "high|medium|low",
          "rationale": "...",
          "per_source": [
            { 
              "url": "...", 
              "source_credibility": "high|medium|low",
              "content_match": "full|partial|none", 
              "notes": "..." 
            }
          ]
        }
        ```
        
5. **UI로 부분 전송**
    - SSE: `POST /api/verification/stream` 으로 붙어있는 클라이언트에 push
    - 또는: 서버가 `PUT /api/ui-sync` 비동기 호출(내부용)
    - 어쨌든 payload는 위에서 정의한 "문단 검증 결과 구조"

### 성능/안전 포인트

- 링크 5개 병렬이면 URL 당 1~2초라도 전체는 문단당 2~3초 안으로 끝남
- GPT 호출 실패 시:
    - confidence: "unknown" 으로 보내고
    - UI는 회색 or 노랑으로 표시
- 출처 신뢰도가 모두 낮을 경우:
    - 내용이 일치하더라도 medium 이상으로 평가하지 않음
    - UI 툴팁에 "출처 신뢰도가 낮습니다" 경고 표시

---

## 병렬 개발 플랜 (요약)

### 계약/스켈레톤

- **공통**: 위 2개 JSON 스키마 고정
- **UI**: Mock JSON으로 문단 카드 리스트 만들기
- **BE1**: `/api/ingest` 만들고 dummy 문단 반환
- **BE2**: 문단→GPT 프롬프트 템플릿만 만들기 (크롤링은 mock)

### 실제 크롤 & 파싱

- **BE1**: ScrapingBee 붙이고 본문/출처 분리 룰 적용
- **UI**: SSE/폴링 중 하나 붙이기
- **BE2**: 링크 5개 병렬 크롤 구현

### 품질화

- 링크가 하나도 없을 때의 처리
- 문단이 너무 길 때 쪼개기
- GPT 응답 근거를 UI 툴팁에 잘 보이게 가공

---

## 마무리 정리

- **UI** 는 "문단 리스트를 빠르게 보여주고, 이후 들어오는 문단별 신뢰도만 덮어쓴다."
- **백엔드 로직1** 은 "URL을 구조화된 문단+링크로 바꿔주는 입구"
- **백엔드 로직2** 는 "각 문단을 실제 출처와 비교해서 신호등 값을 정해주는 뒷단"
- 이 세 개를 위의 JSON 인터페이스로 묶어두면 서로 기다리지 않고 동시에 개발 가능합니다.
